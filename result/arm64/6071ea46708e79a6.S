func0000000000000065:                   // @func0000000000000065
// %bb.0:                               // %entry
	mov	w9, #52429                      // =0xcccd
	add	w8, w2, #2
	movk	w9, #52428, lsl #16
	umull	x8, w8, w9
	add	w9, w0, w1
	lsr	x8, x8, #34
	add	w0, w9, w8
	ret
                                        // -- End function
func000000000000000f:                   // @func000000000000000f
// %bb.0:                               // %entry
	mov	w9, #32811                      // =0x802b
	add	w8, w2, #2
	movk	w9, #10965, lsl #16
	umull	x8, w8, w9
	add	w9, w0, w1
	lsr	x8, x8, #40
	add	w0, w9, w8
	ret
                                        // -- End function
func0000000000000060:                   // @func0000000000000060
// %bb.0:                               // %entry
	mov	w9, #19923                      // =0x4dd3
	add	w8, w2, #500
	movk	w9, #4194, lsl #16
	umull	x8, w8, w9
	add	w9, w0, w1
	lsr	x8, x8, #38
	add	w0, w9, w8
	ret
                                        // -- End function
func0000000000000020:                   // @func0000000000000020
// %bb.0:                               // %entry
	mov	w8, #23292                      // =0x5afc
	mov	w9, #34079                      // =0x851f
	movk	w8, #2628, lsl #16
	movk	w9, #20971, lsl #16
	add	w8, w2, w8
	umull	x8, w8, w9
	add	w9, w0, w1
	lsr	x8, x8, #37
	add	w0, w9, w8
	ret
                                        // -- End function
func0000000000000025:                   // @func0000000000000025
// %bb.0:                               // %entry
	mov	w9, #52429                      // =0xcccd
	add	w8, w2, #2
	movk	w9, #52428, lsl #16
	umull	x8, w8, w9
	add	w9, w0, w1
	lsr	x8, x8, #34
	add	w0, w9, w8
	ret
                                        // -- End function
