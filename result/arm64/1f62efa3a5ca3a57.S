func000000000000005f:                   // @func000000000000005f
// %bb.0:                               // %entry
	fmov	x8, d4
	fmov	x10, d5
	fmov	x13, d2
	fmov	x15, d3
	mov	x9, v4.d[1]
	mov	x11, v5.d[1]
	mov	x12, v2.d[1]
	mov	x14, v3.d[1]
	mul	x8, x8, x8
	mul	x10, x10, x10
	mul	x13, x13, x13
	fmov	d2, x8
	mul	x15, x15, x15
	fmov	d3, x10
	mul	x9, x9, x9
	fmov	d4, x13
	mul	x11, x11, x11
	fmov	d5, x15
	mul	x12, x12, x12
	mov	v2.d[1], x9
	mul	x14, x14, x14
	mov	v3.d[1], x11
	mov	v4.d[1], x12
	mov	v5.d[1], x14
	add	v2.2d, v4.2d, v2.2d
	add	v3.2d, v5.2d, v3.2d
	add	v0.2d, v2.2d, v0.2d
	add	v1.2d, v3.2d, v1.2d
	ret
                                        // -- End function
func0000000000000058:                   // @func0000000000000058
// %bb.0:                               // %entry
	fmov	x8, d4
	fmov	x10, d5
	fmov	x13, d2
	fmov	x15, d3
	mov	x9, v4.d[1]
	mov	x11, v5.d[1]
	mov	x12, v2.d[1]
	mov	x14, v3.d[1]
	mul	x8, x8, x8
	mul	x10, x10, x10
	mul	x13, x13, x13
	fmov	d2, x8
	mul	x15, x15, x15
	fmov	d3, x10
	mul	x9, x9, x9
	fmov	d4, x13
	mul	x11, x11, x11
	fmov	d5, x15
	mul	x12, x12, x12
	mov	v2.d[1], x9
	mul	x14, x14, x14
	mov	v3.d[1], x11
	mov	v4.d[1], x12
	mov	v5.d[1], x14
	add	v2.2d, v4.2d, v2.2d
	add	v3.2d, v5.2d, v3.2d
	add	v0.2d, v2.2d, v0.2d
	add	v1.2d, v3.2d, v1.2d
	ret
                                        // -- End function
func00000000000000a0:                   // @func00000000000000a0
// %bb.0:                               // %entry
	fmov	x8, d4
	fmov	x10, d5
	fmov	x13, d2
	fmov	x15, d3
	mov	x9, v4.d[1]
	mov	x11, v5.d[1]
	mov	x12, v2.d[1]
	mov	x14, v3.d[1]
	mul	x8, x8, x8
	mul	x10, x10, x10
	mul	x13, x13, x13
	fmov	d2, x8
	mul	x15, x15, x15
	fmov	d3, x10
	mul	x9, x9, x9
	fmov	d4, x13
	mul	x11, x11, x11
	fmov	d5, x15
	mul	x12, x12, x12
	mov	v2.d[1], x9
	mul	x14, x14, x14
	mov	v3.d[1], x11
	mov	v4.d[1], x12
	mov	v5.d[1], x14
	add	v2.2d, v4.2d, v2.2d
	add	v3.2d, v5.2d, v3.2d
	add	v0.2d, v2.2d, v0.2d
	add	v1.2d, v3.2d, v1.2d
	ret
                                        // -- End function
