func0000000000000030:                   // @func0000000000000030
// %bb.0:                               // %entry
	mov	w8, #64                         // =0x40
	dup	v6.2d, x8
	sub	v7.2d, v6.2d, v5.2d
	neg	v5.2d, v5.2d
	sub	v6.2d, v6.2d, v4.2d
	neg	v4.2d, v4.2d
	ushl	v1.2d, v1.2d, v7.2d
	ushl	v0.2d, v0.2d, v6.2d
	ushl	v3.2d, v3.2d, v5.2d
	ushl	v2.2d, v2.2d, v4.2d
	orr	v1.16b, v1.16b, v3.16b
	orr	v0.16b, v0.16b, v2.16b
	ret
                                        // -- End function
func0000000000000032:                   // @func0000000000000032
// %bb.0:                               // %entry
	mov	w8, #64                         // =0x40
	dup	v6.2d, x8
	sub	v7.2d, v6.2d, v3.2d
	neg	v3.2d, v3.2d
	sub	v6.2d, v6.2d, v2.2d
	neg	v2.2d, v2.2d
	ushl	v5.2d, v5.2d, v7.2d
	ushl	v4.2d, v4.2d, v6.2d
	ushl	v1.2d, v1.2d, v3.2d
	ushl	v0.2d, v0.2d, v2.2d
	orr	v1.16b, v1.16b, v5.16b
	orr	v0.16b, v0.16b, v4.16b
	ret
                                        // -- End function
func0000000000000034:                   // @func0000000000000034
// %bb.0:                               // %entry
	mov	w8, #64                         // =0x40
	dup	v6.2d, x8
	sub	v7.2d, v6.2d, v5.2d
	neg	v5.2d, v5.2d
	sub	v6.2d, v6.2d, v4.2d
	neg	v4.2d, v4.2d
	ushl	v1.2d, v1.2d, v7.2d
	ushl	v0.2d, v0.2d, v6.2d
	ushl	v3.2d, v3.2d, v5.2d
	ushl	v2.2d, v2.2d, v4.2d
	orr	v1.16b, v1.16b, v3.16b
	orr	v0.16b, v0.16b, v2.16b
	ret
                                        // -- End function
func0000000000000010:                   // @func0000000000000010
// %bb.0:                               // %entry
	mov	w8, #64                         // =0x40
	dup	v6.2d, x8
	sub	v7.2d, v6.2d, v5.2d
	neg	v5.2d, v5.2d
	sub	v6.2d, v6.2d, v4.2d
	neg	v4.2d, v4.2d
	ushl	v1.2d, v1.2d, v7.2d
	ushl	v0.2d, v0.2d, v6.2d
	ushl	v3.2d, v3.2d, v5.2d
	ushl	v2.2d, v2.2d, v4.2d
	orr	v1.16b, v1.16b, v3.16b
	orr	v0.16b, v0.16b, v2.16b
	ret
                                        // -- End function
func0000000000000036:                   // @func0000000000000036
// %bb.0:                               // %entry
	mov	w8, #8                          // =0x8
	dup	v6.2d, x8
	sub	v7.2d, v6.2d, v5.2d
	neg	v5.2d, v5.2d
	sub	v6.2d, v6.2d, v4.2d
	neg	v4.2d, v4.2d
	ushl	v1.2d, v1.2d, v7.2d
	ushl	v0.2d, v0.2d, v6.2d
	ushl	v3.2d, v3.2d, v5.2d
	ushl	v2.2d, v2.2d, v4.2d
	orr	v1.16b, v1.16b, v3.16b
	orr	v0.16b, v0.16b, v2.16b
	ret
                                        // -- End function
