func0000000000000035:                   // @func0000000000000035
// %bb.0:                               // %entry
	add	w8, w0, w0, lsl #1
	add	w8, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000034:                   // @func0000000000000034
// %bb.0:                               // %entry
	add	w8, w0, w0, lsl #1
	add	w8, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000024:                   // @func0000000000000024
// %bb.0:                               // %entry
	mov	w8, #-30                        // =0xffffffe2
	madd	w8, w0, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000004:                   // @func0000000000000004
// %bb.0:                               // %entry
	mov	w8, #-12                        // =0xfffffff4
	madd	w8, w0, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000014:                   // @func0000000000000014
// %bb.0:                               // %entry
	add	w8, w0, w0, lsl #1
	add	w8, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000031:                   // @func0000000000000031
// %bb.0:                               // %entry
	add	w8, w0, w0, lsl #1
	add	w8, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000005:                   // @func0000000000000005
// %bb.0:                               // %entry
	mov	w8, #52                         // =0x34
	madd	w8, w0, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
func0000000000000000:                   // @func0000000000000000
// %bb.0:                               // %entry
	sub	w8, w0, w0, lsl #2
	add	w8, w8, w1
	sxtw	x0, w8
	ret
                                        // -- End function
