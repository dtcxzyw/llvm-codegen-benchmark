func0000000000000000:                   // @func0000000000000000
// %bb.0:                               // %entry
	mov	x8, #50633                      // =0xc5c9
	movk	x8, #49780, lsl #16
	movk	x8, #23290, lsl #32
	movk	x8, #4986, lsl #48
	smulh	x8, x1, x8
	asr	x9, x8, #11
	add	x8, x9, x8, lsr #63
	mov	w9, #-12                        // =0xfffffff4
	madd	x0, x8, x9, x0
	ret
                                        // -- End function
func0000000000000005:                   // @func0000000000000005
// %bb.0:                               // %entry
	mov	x8, #38067                      // =0x94b3
	movk	x8, #9942, lsl #16
	movk	x8, #3048, lsl #32
	movk	x8, #4398, lsl #48
	smulh	x8, x1, x8
	asr	x9, x8, #26
	add	x8, x9, x8, lsr #63
	mov	x9, #-16960                     // =0xffffffffffffbdc0
	movk	x9, #65520, lsl #16
	madd	x0, x8, x9, x0
	ret
                                        // -- End function
func0000000000000004:                   // @func0000000000000004
// %bb.0:                               // %entry
	mov	x8, #-6148914691236517206       // =0xaaaaaaaaaaaaaaaa
	eor	x8, x8, #0x8000000000000001
	smulh	x8, x1, x8
	lsr	x9, x8, #1
	add	x8, x9, x8, lsr #63
	mov	w9, #12                         // =0xc
	madd	x0, x8, x9, x0
	ret
                                        // -- End function
func0000000000000010:                   // @func0000000000000010
// %bb.0:                               // %entry
	lsr	x8, x1, #2
	mov	x9, #-3689348814741910324       // =0xcccccccccccccccc
	movk	x9, #52440
	madd	x0, x8, x9, x0
	ret
                                        // -- End function
func0000000000000014:                   // @func0000000000000014
// %bb.0:                               // %entry
	lsr	x8, x1, #3
	mov	x9, #3689348814741910323        // =0x3333333333333333
	movk	x9, #13112
	madd	x0, x8, x9, x0
	ret
                                        // -- End function
