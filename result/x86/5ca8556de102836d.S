func000000000000000f:
	movzbl	%sil, %eax
	leal	14(%rdi,%rax), %eax
	retq

func0000000000000010:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func0000000000000015:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func0000000000000000:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func0000000000000005:
	movzbl	%sil, %eax
	leal	-1(%rdi,%rax), %eax
	retq

func0000000000000008:
	movzbl	%sil, %eax
	leal	1(%rdi,%rax), %eax
	retq

func0000000000000007:
	movzbl	%sil, %eax
	leal	-14(%rdi,%rax), %eax
	retq

func0000000000000014:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func0000000000000001:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func000000000000001d:
	movzbl	%sil, %eax
	leal	-528(%rdi,%rax), %eax
	retq

func000000000000000d:
	movzbl	%sil, %eax
	leal	-489(%rdi,%rax), %eax
	retq

func0000000000000017:
	movzbl	%sil, %eax
	leal	-48(%rdi,%rax), %eax
	retq

func0000000000000003:
	movzbl	%sil, %eax
	leal	-1(%rdi,%rax), %eax
	retq

func000000000000001f:
	movzbl	%sil, %eax
	leal	1(%rdi,%rax), %eax
	retq

func0000000000000004:
	movzbl	%sil, %eax
	leal	1(%rdi,%rax), %eax
	retq

func000000000000000a:
	movzbl	%sil, %eax
	leal	2(%rdi,%rax), %eax
	retq

func0000000000000018:
	movzbl	%sil, %eax
	leal	2(%rdi,%rax), %eax
	retq

func0000000000000006:
	movzbl	%sil, %eax
	leal	-1(%rdi,%rax), %eax
	retq

func0000000000000002:
	movzbl	%sil, %eax
	leal	1(%rdi,%rax), %eax
	retq

