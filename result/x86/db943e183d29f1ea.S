func0000000000000018:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	1(%rdi,%rax), %rax
	retq

func0000000000000010:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	1(%rdi,%rax), %rax
	retq

func000000000000000b:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	8(%rdi,%rax), %rax
	retq

func0000000000000013:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	1(%rdi,%rax), %rax
	retq

func000000000000001b:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	4(%rdi,%rax), %rax
	retq

func000000000000000c:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	-8(%rdi,%rax,8), %rax
	retq

func000000000000000a:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	-4(%rdi,%rax,4), %rax
	retq

func0000000000000000:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	4(%rdi,%rax,4), %rax
	retq

func000000000000003f:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	12(%rdi,%rax,4), %rax
	retq

func000000000000002b:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	32(%rdi,%rax,4), %rax
	retq

func0000000000000030:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	4(%rdi,%rax,4), %rax
	retq

func0000000000000003:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	4(%rdi,%rax), %rax
	retq

func000000000000001a:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	-4(%rdi,%rax,4), %rax
	retq

func000000000000003b:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	16(%rdi,%rax,2), %rax
	retq

func0000000000000008:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	-4(%rdi,%rax), %rax
	retq

func000000000000003c:
	movslq	%edx, %rax
	imulq	%rsi, %rax
	leaq	8(%rdi,%rax,8), %rax
	retq

